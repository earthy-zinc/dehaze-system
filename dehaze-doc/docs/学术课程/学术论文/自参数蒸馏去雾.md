---
tag: []
title: 'Self-Parameter Distillation Dehazing'
category:
    - 图像去雾
version: 5197
libraryID: 1
itemKey: RF969FL6

---
# 自参数蒸馏去雾

## 摘要

本文提出了一种新颖的基于自蒸馏的去雾方法。<span class="highlight" data-annotation="%7B%22attachmentURI%22%3A%22http%3A%2F%2Fzotero.org%2Fusers%2F10046823%2Fitems%2F9SIX2C8F%22%2C%22pageLabel%22%3A%227%22%2C%22position%22%3A%7B%22pageIndex%22%3A6%2C%22rects%22%3A%5B%5B77.482%2C193.588%2C296.117%2C205.542%5D%2C%5B62.462%2C179.165%2C296.115%2C190.419%5D%2C%5B62.462%2C164.742%2C296.116%2C175.996%5D%2C%5B62.462%2C150.319%2C296.116%2C161.573%5D%2C%5B62.462%2C135.896%2C271.159%2C147.15%5D%5D%7D%2C%22citationItem%22%3A%7B%22uris%22%3A%5B%22http%3A%2F%2Fzotero.org%2Fusers%2F10046823%2Fitems%2FSW4N67ZU%22%5D%2C%22locator%22%3A%227%22%7D%7D" ztype="zhighlight"><a href="zotero://open-pdf/library/items/9SIX2C8F?page=7">“知识蒸馏”的概念是 Hinton 等人［52］于 2015 年提出 来的，其基本思想是将复杂的教师模型学习到的知识 迁移到轻型的学生模型上，指导学生模型的训练和学 习 . 研究结果表明，与教师模型相比，学生模型能以较 低的模型复杂度，获得略逊于甚至于相当的性能 .”</a></span> 本文引入了单个知识蒸馏网络，将网络参数转移到自身进行去雾。在早期阶段，所提出的网络使用无雾数据将场景内容(身份)信息传输到自己的下一阶段。然而，在后期阶段，网络利用雾霾数据向自身传递雾霾信息，从而能够利用前期阶段的场景信息对输入图像进行精确去雾。在单个网络中，从提取全局场景特征到对场景进行去雾，参数都是无缝更新的。在训练过程中，前向传播作为教师网络，后向传播作为学生网络。
