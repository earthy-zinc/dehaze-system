\relax 
\citation{he2010single,cai2016dehazenet,li2017aod}
\citation{liu2019griddehazenet,qin2020ffa}
\citation{guo2022image,song2023vision,yu2021two,jin2022structure,liu2023data}
\citation{esser2021taming}
\citation{hassani2022dilated}
\citation{he2010single}
\citation{zhu2015fast}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{}\protected@file@percent }
\citation{liu2019griddehazenet}
\citation{qin2020ffa}
\citation{yin2023multiscale}
\citation{vaswani2017attention}
\citation{guo2022image}
\citation{song2023vision}
\citation{yu2021two}
\citation{deng2009imagenet}
\citation{zhang2018image}
\citation{jin2022structure}
\citation{dosovitskiy2020image}
\citation{liu2023data}
\citation{guo2023scanet}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An overview of our CMFR-Net. This model consists of two branches: prior matching branch and channel attention branch. Hazy image is processed separately by two branches, each outputting a feature map. Then, a feature fusion tail is used to fuse the feature maps of the two branches, and finally generate a hazy-free image.}}{2}{}\protected@file@percent }
\newlabel{fig0}{{1}{2}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {II}RELATED WORK}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Prior-Based Dehazing Methods}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Learning-Based Dehazing Methods}{2}{}\protected@file@percent }
\citation{kingma2013auto}
\citation{van2017neural}
\citation{esser2021taming}
\citation{wu2023ridcp}
\citation{esser2021taming}
\citation{ronneberger2015u}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Discrete Codebook}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {III}PROPOSED METHOD}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Overall Network Architecture}{3}{}\protected@file@percent }
\newlabel{PMB}{{1}{3}{}{}{}}
\newlabel{CAB}{{2}{3}{}{}{}}
\newlabel{tail}{{3}{3}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Prior Matching Branch}{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The discretization operation of the codebook is shown in the figure. The feature map output by the encoder is discretized to form discrete encoded values, represented by gray rectangles. Each discrete encoded value corresponds to an embedding, and all embeddings are stored in an embedding space, which is the codebook. Using the nearest neighbor algorithm to obtain the true embedding in the codebook, represented as a colored rectangular prism, as input to the decoder.}}{4}{}\protected@file@percent }
\newlabel{fig2}{{2}{4}{}{}{}}
\newlabel{vq_equation_1}{{4}{4}{}{}{}}
\newlabel{vq_equation_2}{{5}{4}{}{}{}}
\newlabel{vq_equation_3}{{6}{4}{}{}{}}
\newlabel{codebook_matching_equation_2}{{7}{4}{}{}{}}
\newlabel{codebook_matching_equation_1}{{8}{4}{}{}{}}
\citation{dosovitskiy2020image}
\citation{hassani2023neighborhood,hassani2022dilated}
\citation{vaswani2017attention}
\citation{liu2021swin}
\citation{qin2020ffa}
\citation{qu2019enhanced}
\newlabel{NA_operation}{{9}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of our Feature-Refined Decoder (FRD), which consists of upsampling layers, convolutions, residual blocks, channel attention and pixel attention blocks, as well as an enhancer block. }}{5}{}\protected@file@percent }
\newlabel{fig3}{{3}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Detail network structure of the Enhancer Block.}}{5}{}\protected@file@percent }
\newlabel{fig4}{{4}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Channel Attention Branch}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Loss Function}{5}{}\protected@file@percent }
\citation{simonyan2014very}
\citation{johnson2016perceptual}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visual examples in dataset O-HAZE. From left to right are hazy images, advanced methods for comparison and our method result, and Ground Truth.}}{6}{}\protected@file@percent }
\newlabel{fig6}{{5}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visual examples in dataset DENSE-HAZE. From left to right are hazy images, advanced methods for comparison and our method result, and Ground Truth.}}{6}{}\protected@file@percent }
\newlabel{fig7}{{6}{6}{}{}{}}
\newlabel{vq_loss}{{10}{6}{}{}{}}
\newlabel{reconstruction_loss}{{11}{6}{}{}{}}
\citation{zhu2017unpaired}
\citation{chen2022real}
\citation{simonyan2014very}
\citation{gondal2019unreasonable}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Visual examples in dataset NH-HAZE-20. From left to right are hazy images, advanced methods for comparison and our method result, and Ground Truth.}}{7}{}\protected@file@percent }
\newlabel{fig8}{{7}{7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Visual examples in dataset NH-HAZE-21. From left to right are hazy images, advanced methods for comparison and our method result, and Ground Truth.}}{7}{}\protected@file@percent }
\newlabel{fig9}{{8}{7}{}{}{}}
\newlabel{perceptual_loss}{{12}{7}{}{}{}}
\newlabel{adversarial_loss}{{13}{7}{}{}{}}
\newlabel{codebook_loss}{{14}{7}{}{}{}}
\citation{simonyan2014very}
\citation{he2010single}
\citation{li2017aod}
\citation{chen2019gated}
\citation{qin2020ffa}
\citation{yu2021two}
\citation{guo2022image}
\citation{jin2022structure}
\citation{guo2023scanet}
\citation{cui2024revitalizing}
\citation{ancuti2018ohaze}
\citation{ancuti2019dense}
\citation{ancuti2020ntire}
\citation{ancuti2021ntire}
\citation{ancuti2023ntire}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Visual examples in dataset NH-HAZE-23. From left to right are hazy images, advanced methods for comparison and our method result, and Ground Truth.}}{8}{}\protected@file@percent }
\newlabel{fig10}{{9}{8}{}{}{}}
\newlabel{encoder_loss}{{15}{8}{}{}{}}
\newlabel{rest_loss}{{16}{8}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}EXPERIMENTS}{8}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Datasets}{8}{}\protected@file@percent }
\citation{kingma2014adam}
\citation{wang2004image}
\citation{zhang2018unreasonable}
\citation{he2010single}
\citation{li2017aod}
\citation{chen2019gated}
\citation{qin2020ffa}
\citation{yu2021two}
\citation{guo2022image}
\citation{jin2022structure}
\citation{guo2023scanet}
\citation{cui2024revitalizing}
\citation{liu2023data}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Quantitative Comparison Results of Various Dehazing Methods and Proposed Method on I-HAZE, O-HAZE, DENSE-HAZE, NH-HAZE-20, NH-HAZE-21 and NH-HAZE-23. \textbf  {Bold} Indicates the Best and \underline  {Underline} Indicates the Second Best.}}{9}{}\protected@file@percent }
\newlabel{table_compare_with_benchmarks}{{I}{9}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces The details of the datasets used in our experiments}}{9}{}\protected@file@percent }
\newlabel{table_dataset}{{II}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Implementation Details}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Evaluation Metrics and Competitors}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-D}}Quantitative Evaluations on Benchmarks}{9}{}\protected@file@percent }
\citation{liang2021swinir}
\bibstyle{IEEEtran}
\bibdata{references}
\bibcite{he2010single}{1}
\bibcite{cai2016dehazenet}{2}
\bibcite{li2017aod}{3}
\bibcite{liu2019griddehazenet}{4}
\bibcite{qin2020ffa}{5}
\bibcite{guo2022image}{6}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Ablation study on the proposed network performance after gradually add modules. The scores are evaluated on NH-HAZE-20 dataset. \textbf  {Bold} indicates the best and \underline  {underline} indicates the second best.}}{10}{}\protected@file@percent }
\newlabel{Ablation_study_1}{{III}{10}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-E}}Ablation Study}{10}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The ablation experiments on the NH-HAZE-20 dataset show the PSNR variation curves for different experimental configurations as the number of iterations increases.}}{10}{}\protected@file@percent }
\newlabel{Ablation_study_2}{{10}{10}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}CONCLUSION}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{10}{}\protected@file@percent }
\bibcite{song2023vision}{7}
\bibcite{yu2021two}{8}
\bibcite{jin2022structure}{9}
\bibcite{liu2023data}{10}
\bibcite{esser2021taming}{11}
\bibcite{hassani2022dilated}{12}
\bibcite{zhu2015fast}{13}
\bibcite{yin2023multiscale}{14}
\bibcite{vaswani2017attention}{15}
\bibcite{deng2009imagenet}{16}
\bibcite{zhang2018image}{17}
\bibcite{dosovitskiy2020image}{18}
\bibcite{guo2023scanet}{19}
\bibcite{kingma2013auto}{20}
\bibcite{van2017neural}{21}
\bibcite{wu2023ridcp}{22}
\bibcite{ronneberger2015u}{23}
\bibcite{hassani2023neighborhood}{24}
\bibcite{liu2021swin}{25}
\bibcite{qu2019enhanced}{26}
\bibcite{simonyan2014very}{27}
\bibcite{johnson2016perceptual}{28}
\bibcite{zhu2017unpaired}{29}
\bibcite{chen2022real}{30}
\bibcite{gondal2019unreasonable}{31}
\bibcite{chen2019gated}{32}
\bibcite{cui2024revitalizing}{33}
\bibcite{ancuti2018ohaze}{34}
\bibcite{ancuti2019dense}{35}
\bibcite{ancuti2020ntire}{36}
\bibcite{ancuti2021ntire}{37}
\bibcite{ancuti2023ntire}{38}
\bibcite{kingma2014adam}{39}
\bibcite{wang2004image}{40}
\bibcite{zhang2018unreasonable}{41}
\bibcite{liang2021swinir}{42}
\gdef \@abspage@last{11}
