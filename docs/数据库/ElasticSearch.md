# ElasticSearch 练习

## 基础概念

* Near RealTime：近似实时的搜索
* Cluster集群：一个季军由一个唯一的名字表示，具有相同集群名的结点才会组成一个集群，集群的名称可以在配置文件中指定
* Node结点：结点是存储集群的数据，参与集群的索引和搜索功能。集群有名字，结点也有子集的名字。一个节点也可以是个集群
* Index索引：一个索引是文档的集合，每个索引都哟唯一的名字，我们通过名字来操作索引，一个集群中可以有任意多个索引
* Document文档：是被索引的数据，每个索引都对应一个或多个文档。json格式
* Shard分片：创建一个索引时，我们可以指定文档分成多少个分片来存储，每个分片本身就是一个独立的索引可以放在集群的任意结点上
* Replication备份：一个分片可以有多个备份

| 关系型数据库 | ElasticSearch |
| ------------ | ------------- |
| 数据库       |               |
|              |               |
|              |               |
|              |               |
|              |               |
|              |               |

ElasticSearch是一个分布式的文档存储中间件，他不会将信息储存为项MySQL的那么重列数据行，而是储存已序列化为JSON文档的复杂数据结构。当你在一个集群中有多个结点时，储存的文档分布在整个集群里面，并且可以从任意结点去访问。

当文档被储存后，ElasticSearch将为文档建立索引并且该文档可以被实时的搜索，它使用一种被称为倒排索引的数据结构，这种结构支持快速全文搜索。在倒排索引里列出了所有文档中出现的每一个唯一单词并分别标识了每个单词在哪一个文档中。

索引可以被认为是文档的优化集合每个文档索引都是字段的集合，这些字段是包含了数据的键值对。默认情况，ElasticSearch为每个字段中所有数据建立倒排索引，并且每个索引字段都有专门的优化数据结构。

为不同的目的以不同的方式对同一字段建立索引通常比较有用。ElasticSearch索引只是一个或多个物理碎片的逻辑分组，其中每个碎片都是一个独立的索引。通过将索引中的文档分布在多个碎片上，并将这些碎片分不到多个节点上，ElasticSearch就能够实现冗余功能，这样既可以防止硬件故障，又可以在添加结点到集群时，增加查询能力。随着集群的增长，ElasticSearch会自动迁移碎片以重新平衡集群。

分片有两种类型：主分片和副本分片，索引中的每个文档都有一个主分片，副本分片是主分片的副本，副本分片可以提供数据的冗余副本，以防止硬件故障并增加处理读取请求的能力。

创建索引时，索引中主分片的数量是固定的，但是副本分片数量是可以随时更改的。其更改操作不会中断索引或者查询。

## 基础操作

### RESTful

指的是一组架构约束条件和原则。客户端和服务器之间的交互在请求之间是无状态的，从客户端到服务器的每个请求都要包含理解请求所必须的信息。如果服务器在请求之间的任何时间点重启，客户端不会得到通知。无状态的请求可以由任何可用的服务器回应，而不仅仅局限于某一台。

在服务器端，应用程序的状态和功能可以分为各种资源，每个资源都使用URI得到一个唯一的地址，所有资源都共享同一个接口，以便在客户端和服务器之间传输状态，通信使用的是标准的HTTP方法。

在这种情况下，每个资源都有一个地址，资源本身是方法调用的目标。

### 数据格式

ElasticSearch是面向文档的数据库，一条数据就是一个文档。

### RESTful操作

为方便期间下面用中括号标记的表示语法规则，而不是具体的名称。其中在7.X版本中类型的默认为`_doc`我们通常不应该再更改它。

| 方法                                  | 说明                                                         |
| ------------------------------------- | ------------------------------------------------------------ |
| GET `/_cat/indices?v`                 | 查看所有索引                                                 |
| PUT `/{indices}`                      | 创建索引，相当于创建数据库                                   |
| GET `/{indices}`                      | 查看单个索引                                                 |
| DELETE `/{indices}`                   | 删除一个索引                                                 |
| --------------                        | ---------------------------                                  |
| POST `/{indices}/{_doc}`              | 创建文档，需要以JSON形式在请求体中传入文档内容，如果不指定文档id将会随机生成一个 |
| POST `/{indices}/{_doc}/{id}`         | 创建/修改文档，指定文档id，修改时如果和原文档不同，将会覆盖原文档 |
| GET `/{indices}/{_doc}/{id}`          | 查询文档，需要指定文档id                                     |
| POST `/{indices}/{_doc}/{id}/_update` | 更新文档中某一部分，此操作只会更新传入的局部内容，对于原文档已有的其他内容会保留 |
| DELETE `/{indices}/{_doc}/{id}`       | 删除文档，但并不会立即从磁盘删除，逻辑删除                   |
| POST `/{indices}/_delete_by_query`    | 条件删除文档，需要在请求体中传入删除条件^①^                  |
| ------------                          | --------------------                                         |
| PUT `/{indices}/_mapping`             | 创建映射，类似于数据库中的表结构，有哪些字段、都什么约束信息，需要在请求体中传入约束条件^②^ |
| GET `/{indices}/_mapping`             | 查看映射                                                     |
| ---------------                       | ------------                                                 |
| GET `/{indices}/_search`              | 查询所有文档，按条件查询需要传入查询条件                     |
|                                       |                                                              |
|                                       |                                                              |
|                                       |                                                              |

#### ① 查询条件

```json
{
    // 查询指定字段(数组方式)，如果只想查询文档中部分字段，就需要添加_source进行过滤
    "_source": ["{fieldName1}", "{fieldName2}"],
    // 查询指定字段(对象方式)，如果只想查询文档中部分字段，就需要添加_source进行过滤
    "_source": {
        "includes": [],
        "excludes": []
    }
    // 查询语句
    "query": {
        //精确匹配语句，按某个字段的值匹配，如果给定多个字段，是或（or）的关系
        "match": {
            "{fieldName}": "{value}",
            "{fieldName2}": "{value2}"
        },
        // 在多个字段中按值查询语句
        "multi_match": {
            "query": "{value}",
            "fields": ["{fieldName1}", "{fieldName2}"]
        },
        // 关键字精确查询，不会对查询条件进行分词
        "term": {
            "{fieldName}" :{
                "value": "{value}"
            }
        },
        // 多关键字精确查询
        "terms":{
            "{fieldName}": ["{value1}", "{value2}"]
        }
        // 组合查询语句通过bool关键字把must,must_not, should进行组合查询
		"bool": {
            "must": [{
                "match": {}
            },
            {
               "match": {} 
            }],
            "must_not": [],
            "should": []
        },
		// 范围查询，range关键字查询找出落在指定区间内的数字或者时间，gt(greater than), gte(greater than and equal), lt(less than), lte(less than and equal)
		"range": {
            "{fieldName}": {
                "gte": Number,
                "lte": Number
            }
        },
		// 模糊查询fuzzy，返回于搜索字词相似的文档
		"fuzzy": {
            "{fieldName}": {
                "value": "{value}"
                // 模糊度设置，默认为auto
                "fuzziness": Number
            }
        },
		//  按字段排序，多个字段按照从上到下的优先级进行排序
		"sort": [{
            "{fieldName}": {
                "order": "desc" //或者asc
            }
        }],
		// 对查询内容中的关键字部分，进行标签和样式的设置
		"highlight": {
            "pre_tags": "<font color='red'>",
            "post_tags": "</font>",
            //声明需要高亮的字段
            "fields": {
                "{fieldName}": {}
            }
        },
		// 分页查询字段，从第几页开始，每页显示多少条
		"from": Number,
		"size": Number,
		// 聚合查询aggs，聚合关键字max,min,sum,avg,cardinality,stats*(一次返回前五个指标)，terms*(分组统计)
		"aggs": {
            "{aggs_fieldName}": {
                "{聚合关键字}": {
                    "field": "{fieldName}"
                }
            }
        }
	}	
}
```

#### ② 映射类型

* 字段名field
* 类型type：
  * String：text 可分词，keyword 不可分词
  * Numerical：数值类型，long、integer、short、byte、double、float等
  * Date：日期类型
  * Array：数组类型
  * Object：对象
* 索引index：是否索引，默认为true
* 存储Store：是否独立存储，独立存储会占用更多存储空间，但会更快
* 分词器analyzer：使用哪一种分词器

## 环境集群

### 概念

**集群**：一个集群是由一个或者多个服务器结点组织在一起，共同持有整个数据，并一起提供索引和搜索功能，一个ElasticSearch集群有一个唯一的名字标识。一个单独的服务器结点要通过集群名称来加入这个集群。

**结点**：结点作为集群的一部分，存储一部分数据，参与集群的索引和搜索功能。一个结点也有一个名字表示。默认情况下，每个结点都会被安排加入到一个叫做"elasticsearch"的集群中。

**索引**：一个索引就是一个拥有几分相似特征的文档的集合。一个索引由一个名字来标识（小写字母），当我们要对这个索引中的文档进行索引、搜索、更新、删除时都需要使用名字。在一个集群中我们可以定义任意多的索引。

**类型**：类型时索引在逻辑上的分类或分区。

**文档**：一个文档是一个可以被索引的基础信息单元，也就是一条数据，在一个索引中也可以存储任意多的文档。文档已Json格式表示。

**字段**：是文档中的内容，一般就是json格式中键值对中的键，代表了字段

**映射**：映射是对文档数据处理的方式或者存储规则方面做出的一些限制，比如说某个字段的数据类型、默认值、字段文本分析器、是否允许被索引这些规则。每个具体的数据集其目的、数据结构不同，都有其特点。因此建立这种存储规则对性能提高很大。

**分片**：一个索引中可能会包含很多文档，可能会存储超过单个结点硬件限制的大量数据。导致单个结点存储不下，响应数据太慢，为了解决这样的问题，ElasticSearch提供了可以将单个索引划分为多份的能力，这样划分过程（划分的每一份数据）就称为分片，在创建索引的时候，就可以指定想要分片的数量。每个分片本身也是一个功能完善并且独立的索引，这个索引可以被放在集群的任何一个结点上。分片允许我们水平分割，扩展存储容量，允许我们在分片之上进行分布式的、并行的操作，进而提高性能和吞吐量。

**副本（Replicas）**：我们可以创建分片的副本，在分片或者结点失败的情况下，有一个源数据的副本还存在，提高了可用性。扩展了搜索量和吞吐量，因为搜索也可以在副本上并行运行。

### 系统架构

一个运行中的ElasticSearch叫做一个结点，而结点是一个或多个拥有相同集群名称的结点组成，他们共同承担数据和负载的压力，当有节点加入集群或者从集群中移除某一结点时，集群会重新平均分布所有数据。

当一个结点被选举成为主节点时，他将负责管理集群范围内的所有变更，如增加或删除索引，增加或删除结点。而主节点并不需要涉及文档级别的操作。

作为用户我们可以将请求发送到集群中的任何结点，每个结点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的结点。无论我们将请求发送到哪一个结点，他都能负责从各个包含我们所需文档的结点中收集到数据。

### 分片原理

ElasticSearch中文本字段中每个单词都需要被搜索，对数据库意味着需要单个字段有索引多值的能力。最好的支持是一个字段多个值这种需求的数据结构为倒排索引。

正向索引是搜索引擎会将待搜索的文件都对应一个文件ID，搜索时这个ID和搜索关键字对应，然后对关键字进行统计计数。但是文档数目很多，这样的索引结构无法满足实时返回排名结果的要求，所以，搜索引擎会将正向索引重新构建为倒排索引，把文件ID对应到关键字的映射转换为关键词到文件ID的映射，每个关键字都对应者一系列文件，这些文件中都出现了这个关键词。

一个倒排索引由文档中所有不重复词的列表构成，对于其中的每一个词，都有一个包含这个词的文档列表。

这些词中间可能会由大小写，同义词，单复数的问题，我们需要对词进行标准化，然后再搜索时，也要标准化关键字。分词和标准化的过程称为分析。

### 文档搜索

早期全文检索会为整个文档集合建立一个很大的倒排索引并写入磁盘，一旦新的索引就绪，旧的就会被替换。倒排索引一般是不变的，不变性有以下价值：不需要锁，不需要担心多进程同时修改数据的问题。一旦索引被读入内核文件系统缓存，便会留在那里，由于其不变性，只要文件系统缓存中还有足够的空间，那么大部分读请求就会直接请求内存，而不会命中磁盘。写入单个大的倒排索引允许被压缩，在索引的生命周期内始终有效，他们不需要每次数据改变的时候被重建。

但是这时候如果要让一个新的文档可以被搜索到，就需要重建索引。

### 动态更新索引

在保留不变性的前提下实现倒排索引的更新，我们可以使用更多的索引，通过增加新的补充索引来反映新近的修改，而不是直接重写整个倒排索引。每个倒排索引都会被轮流查询到，从最早的开始查询完成之后，在对结果合并。

按段搜索：每一段都是一个倒排索引，但是索引在除了表示所有段的集合外，还增加了提交点的概念，一个列出了所有已知段的文件。

1. 新文档被收集到内存索引缓存
2. 缓存被提交，一个追加的倒排索引被写入磁盘
3. 新的段被开启，让它包含的文档可见，可以被搜索到
4. 内存缓存被清空，等待接收新的文档

当一个查询被触发，所有已知的段按照顺序被查询。词项统计会对所有段的结果进行聚合，保证每个词和每个文档的关联都被准确的计算。段是不可改变的，所以既不能从文档中把旧的段移除，也不能修改旧的段来反应文档的更新。但是每个提交点会保留一个del文件，这些文件存有被删除文档的段信息。

### 近实时搜索

随着按段搜索的发展，一个新的文档从索引到可以被搜索的延迟显著降低了，新的文档在几分钟之内既可以被检索，但是还不够快，磁盘成了瓶颈。提交一个新的段到磁盘需要fsync来确保段被物理性的写入磁盘。但是这种操作代价很大。我们需要更轻量的方式来使一个文档可被搜索。

在ElasticSearch中，写入和打开一个新段的轻量级过程叫做refresh，默认情况下，每个分片会每秒刷新一次，文档的变化并不是立即对搜索可见，但是会在一秒内变为可见。

但是有时并没有那么看重近实时搜索功能，我们想要优化系统性能，索引速度，这是可以通过设置refresh_interval降低索引的刷新频率。

### 持久化变更

为了保证数据可靠性，需要确保数据变化被持久化到了磁盘。一次完整的提交会将段写入磁盘，并且写入一个包含所有段列表的提交键，ElasticSearch在启动或者 重新打开一个索引的过程中使用这个提交点来判断那些段隶属于当前分片。

即使通过每秒刷新实现了近实时搜索，我们仍然需要经常进行完整提交来确保能够从失败中恢复。

// TODO 内部的实现流程

### 文档分析

 分析包含下面的过程：

1. 将一块文本分成适合于倒排索引的独立词条
2. 将这些词条统一化为标准格式以提高他们的可搜索性

这些功能的实现主要由以下这几个部分构成：

1. 字符过滤器，字符串按照顺序通过每个字符过滤器，主要目的是在分词前整理字符串，比如去掉HTML代码，去掉一些符号等
2. 分词器，将句子分割成单个的词条
3. Token过滤器，词条按照顺序通过过滤器，这一步会规范化词条（如将过去式改为原始形态，大写字母统一改成小写）、删除词条（删除一些无用词）、增加词条（增加同义词，以确保满足用户搜索需求）

### 分析器的使用场景

当我们索引一个文档，他的全文于被分析成词条用以创建倒排索引。但是当我们在全文域搜索的时候，我们需要将查询字符串通过相同的分析过程，以保证我们搜索的词条格式与索引中的词条格式一致。

当你查询全文域时，会对查询字符串应用分析器，以产生正确搜索词条列表。当你查询一个精确值域时，不会分析查询字符串，而是搜索你指定的精确值。

### 测试分析器

```
GET /analyze
{
	"analyzer": "standard",
	"text": "text to analyze"
}
```

### 自定义分析器

## 文档处理

## SpringData 框架集成

配置类：我们需要自定义配置类，继承AbstractElasticsearchConfiguration，并实现 elasticsearchClient()抽象方法，创建 RestHighLevelClient 对象。
